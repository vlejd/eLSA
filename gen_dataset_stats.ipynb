{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from itertools import chain \n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(examples):\n",
    "    words = list(chain(*examples))\n",
    "    c = Counter(words)\n",
    "    sc = sorted(list(c.items()))\n",
    "    slens = [len(x) for x in examples]\n",
    "    return {\n",
    "        \"#words\": len(words),\n",
    "        \"#unique words\": len(c),\n",
    "        \"\\specialcell{#words with\\\\\\\\$1$ apperance}\": len([x for x in c if c[x]==1]),\n",
    "        \"#examples\": len(examples),\n",
    "        \"\\specialcell{avg sentence\\\\\\\\length}\": np.mean(slens),\n",
    "        \"\\specialcell{max sentence\\\\\\\\length}\": np.max(slens),\n",
    "        \"\\specialcell{median sentence\\\\\\\\length}\": np.median(slens),        \n",
    "        \"counter\": c\n",
    "    }\n",
    "\n",
    "def explore_dataset(dataset):\n",
    "    # number of tokens\n",
    "    # number of unique tokens\n",
    "    # same for positive, and negative\n",
    "    stats = get_stats(dataset.samples)\n",
    "    mean = np.mean(dataset.labels)\n",
    "    stats['bias'] = max(mean, 1-mean)\n",
    "    del stats['counter']\n",
    "    return stats\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats = {}\n",
    "for dataset in datasets.ALL_DATASETS+[datasets.TRECDataset()]:\n",
    "    all_stats[dataset.name()[:-7]] = explore_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CR</th>\n",
       "      <th>MPQA</th>\n",
       "      <th>MR</th>\n",
       "      <th>SUBJ</th>\n",
       "      <th>TRECDatas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#examples</th>\n",
       "      <td>3775.000000</td>\n",
       "      <td>10606.000000</td>\n",
       "      <td>10662.000000</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>5952.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#unique words</th>\n",
       "      <td>5674.000000</td>\n",
       "      <td>6238.000000</td>\n",
       "      <td>20325.000000</td>\n",
       "      <td>22636.0000</td>\n",
       "      <td>8968.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#words</th>\n",
       "      <td>75932.000000</td>\n",
       "      <td>32779.000000</td>\n",
       "      <td>230162.000000</td>\n",
       "      <td>246015.0000</td>\n",
       "      <td>58468.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\specialcell{#words with\\\\$1$ apperance}</th>\n",
       "      <td>2714.000000</td>\n",
       "      <td>3117.000000</td>\n",
       "      <td>10160.000000</td>\n",
       "      <td>11152.0000</td>\n",
       "      <td>5338.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\specialcell{avg sentence\\\\length}</th>\n",
       "      <td>20.114437</td>\n",
       "      <td>3.090609</td>\n",
       "      <td>21.587132</td>\n",
       "      <td>24.6015</td>\n",
       "      <td>9.823253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\specialcell{max sentence\\\\length}</th>\n",
       "      <td>106.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>122.0000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\specialcell{median sentence\\\\length}</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias</th>\n",
       "      <td>0.637616</td>\n",
       "      <td>0.687724</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.984039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    CR          MPQA  \\\n",
       "#examples                                  3775.000000  10606.000000   \n",
       "#unique words                              5674.000000   6238.000000   \n",
       "#words                                    75932.000000  32779.000000   \n",
       "\\specialcell{#words with\\\\$1$ apperance}   2714.000000   3117.000000   \n",
       "\\specialcell{avg sentence\\\\length}           20.114437      3.090609   \n",
       "\\specialcell{max sentence\\\\length}          106.000000     44.000000   \n",
       "\\specialcell{median sentence\\\\length}        18.000000      2.000000   \n",
       "bias                                          0.637616      0.687724   \n",
       "\n",
       "                                                     MR         SUBJ  \\\n",
       "#examples                                  10662.000000   10000.0000   \n",
       "#unique words                              20325.000000   22636.0000   \n",
       "#words                                    230162.000000  246015.0000   \n",
       "\\specialcell{#words with\\\\$1$ apperance}   10160.000000   11152.0000   \n",
       "\\specialcell{avg sentence\\\\length}            21.587132      24.6015   \n",
       "\\specialcell{max sentence\\\\length}            62.000000     122.0000   \n",
       "\\specialcell{median sentence\\\\length}         21.000000      23.0000   \n",
       "bias                                           0.500000       0.5000   \n",
       "\n",
       "                                             TRECDatas  \n",
       "#examples                                  5952.000000  \n",
       "#unique words                              8968.000000  \n",
       "#words                                    58468.000000  \n",
       "\\specialcell{#words with\\\\$1$ apperance}   5338.000000  \n",
       "\\specialcell{avg sentence\\\\length}            9.823253  \n",
       "\\specialcell{max sentence\\\\length}           37.000000  \n",
       "\\specialcell{median sentence\\\\length}         9.000000  \n",
       "bias                                          0.984039  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = pd.DataFrame(all_stats)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{l|rrrrr}\n",
      "\\toprule\n",
      "{} &        CR &      MPQA &         MR &      SUBJ &  TRECDatas \\\\\\hline\n",
      "\\midrule\n",
      "\\#examples                                &   3775 &  10606 &   10662 &   10000 &    5952 \\\\\\hline\n",
      "\\#unique words                            &   5674 &   6238 &   20325 &   22636 &    8968 \\\\\\hline\n",
      "\\#words                                   &  75932 &  32779 &  230162 &  246015 &   58468 \\\\\\hline\n",
      "\\specialcell{\\#words with\\\\$1$ apperance} &   2714 &   3117 &   10160 &   11152 &    5338 \\\\\\hline\n",
      "\\specialcell{avg sentence\\\\length}       &     20.11 &      3.09 &      21.59 &      24.60 &       9.82 \\\\\\hline\n",
      "\\specialcell{max sentence\\\\length}       &    106 &     44 &      62 &     122 &      37 \\\\\\hline\n",
      "\\specialcell{median sentence\\\\length}    &     18 &      2 &      21 &      23 &       9 \\\\\\hline\n",
      "bias                                     &      0.64 &      0.69 &       0.50 &       0.50 &       0.98 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(all_stats).round(2)\n",
    "df.loc['bias']['TREC'] = None\n",
    "raw_tex = df.to_latex() \n",
    "raw_tex = raw_tex.replace('textbackslashspecialcell\\\\','specialcell')\n",
    "raw_tex = raw_tex.replace('textbackslash','')\n",
    "raw_tex = raw_tex.replace('length\\\\','length')\n",
    "raw_tex = raw_tex.replace('apperance\\\\','apperance')\n",
    "raw_tex = raw_tex.replace('.000','')\n",
    "raw_tex = raw_tex.replace('.00','')\n",
    "raw_tex = raw_tex.replace('.0 &',' &')\n",
    "raw_tex = raw_tex.replace('lrrrr','l|rrrr')\n",
    "raw_tex = raw_tex.replace('\\\\\\\\','\\\\\\\\\\hline')\n",
    "raw_tex = raw_tex.replace('\\hlinelength','length')\n",
    "raw_tex = raw_tex.replace('.0 \\\\\\\\\\hline', ' \\\\\\\\\\hline ')\n",
    "raw_tex = raw_tex.replace('\\\\hline\\n\\\\bottomrule', '\\n\\\\bottomrule')\n",
    "raw_tex = raw_tex.replace('SUBJ \\\\\\\\\\\\hline', 'SUBJ \\\\\\\\')\n",
    "raw_tex = raw_tex.replace('0.5 &', '0.50 &')\n",
    "raw_tex = raw_tex.replace('24.6 &','24.60 &')\n",
    "raw_tex = raw_tex.replace('words with\\\\\\\\\\\\hline\\$1\\\\$','words with\\\\\\$1$')\n",
    "\n",
    "print(raw_tex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_stats = {} \n",
    "for lab in datasets.TRECDataset.SUPPORTED_LABELS:\n",
    "    dataset = datasets.TRECDataset(task_label=lab)\n",
    "    trec_stats[dataset.name().replace('TRECDataset-','')] = explore_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABBR</th>\n",
       "      <th>DESC</th>\n",
       "      <th>ENTY</th>\n",
       "      <th>HUM</th>\n",
       "      <th>LOC</th>\n",
       "      <th>NUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bias</th>\n",
       "      <td>0.984039</td>\n",
       "      <td>0.781586</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.783602</td>\n",
       "      <td>0.846102</td>\n",
       "      <td>0.830477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ABBR      DESC      ENTY       HUM       LOC       NUM\n",
       "bias  0.984039  0.781586  0.774194  0.783602  0.846102  0.830477"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = pd.DataFrame(trec_stats)\n",
    "q.loc[['bias']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} &  ABBR &  DESC &  ENTY &   HUM &   LOC &   NUM \\\\\n",
      "\\midrule\n",
      "bias &  0.98 &  0.78 &  0.77 &  0.78 &  0.85 &  0.83 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(trec_stats).loc[['bias']].round(2)\n",
    "raw_tex = df.to_latex() \n",
    "print(raw_tex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESC how did serfdom develop in and then leave russia ?\n",
      "HUM what contemptible scoundrel stole the cork from my lunch ?\n",
      "NUM when was ozzy osbourne born ?\n",
      "ENTY what films featured the character popeye doyle ?\n",
      "LOC what sprawling u.s. state boasts the most airports ?\n",
      "ABBR what is the full form of .com ?\n"
     ]
    }
   ],
   "source": [
    "for lab in datasets.TRECDataset.SUPPORTED_LABELS:\n",
    "    d = datasets.TRECDataset(task_label=lab)\n",
    "    print(lab, \" \".join(d.positives[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRDataset\n",
      "\\emph{im a more happier person after discovering the i/p button ! .}\n",
      "\n",
      "\\emph{weaknesses are minor : the feel and layout of the remote control are only so-so ; . it does n 't show the complete file names of mp3s with really long names ; . you must cycle through every zoom setting ( 2x , 3x , 4x , 1/2x , etc . ) before getting back to normal size [ sorry if i 'm just ignorant of a way to get back to 1x quickly ] .}\n",
      "\n",
      "MRDataset\n",
      "\\emph{the rock is destined to be the 21st century 's new `` conan `` and that he 's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .}\n",
      "\n",
      "\\emph{simplistic , silly and tedious .}\n",
      "\n",
      "SUBJDataset\n",
      "\\emph{the movie begins in the past where a young boy named sam attempts to save celebi from a hunter .}\n",
      "\n",
      "\\emph{smart and alert , thirteen conversations about one thing is a small gem .}\n",
      "\n",
      "MPQADataset\n",
      "\\emph{are also being encouraged}\n",
      "\n",
      "\\emph{complaining}\n",
      "\n",
      "CRDataset\n",
      "\\emph{but , if you 're looking for my opinion of the apex dvd player , i love it ! .}\n",
      "\n",
      "\\emph{many of our disney movies do n 't play on this dvd player .}\n",
      "\n",
      "MRDataset\n",
      "\\emph{the gorgeously elaborate continuation of `` the lord of the rings `` trilogy is so huge that a column of words can not adequately describe co-writer/director peter jackson 's expanded vision of j . r . r . tolkien 's middle-earth .}\n",
      "\n",
      "\\emph{it 's so laddish and juvenile , only teenage boys could possibly find it funny .}\n",
      "\n",
      "SUBJDataset\n",
      "\\emph{emerging from the human psyche and showing characteristics of abstract expressionism , minimalism and russian constructivism , graffiti removal has secured its place in the history of modern art while being created by artists who are unconscious of their artistic achievements .}\n",
      "\n",
      "\\emph{color , musical bounce and warm seas lapping on island shores . and just enough science to send you home thinking .}\n",
      "\n",
      "MPQADataset\n",
      "\\emph{it had to happen and the sooner the better}\n",
      "\n",
      "\\emph{failing to support}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets.ALL_DATASETS:\n",
    "    print(dataset.name())\n",
    "    print('\\\\emph{'+' '.join(dataset.positives[0])+'}')\n",
    "    print()\n",
    "    print('\\\\emph{'+' '.join(dataset.negatives[0])+'}')\n",
    "    print()\n",
    "    \n",
    "for dataset in datasets.ALL_DATASETS:\n",
    "    print(dataset.name())\n",
    "    print('\\\\emph{'+' '.join(dataset.positives[1])+'}')\n",
    "    print()\n",
    "    print('\\\\emph{'+' '.join(dataset.negatives[1])+'}')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diplomka",
   "language": "python",
   "name": "diplomka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
